This repository is for a reinforcement learning bot that can learn to trade crypto on live data. It uses Deep Q Learning to make decisions that will increase it's reward after each epsiode it performs. As of right now the repository contains three files. A script that fetches live Bitcoin data that the bot can use while running, a script that initially creates and begins to train the bot for however long you want, and a script that takes the trained bot and continues to train it and produces a new refined model. 

The web scraper for the Bitcoin data creates a CSV file and writes timestamp, price, market cap, fully diluted market cap, volume, volume/market cap, ciculating supply, and max supply data. The bot uses this by reading the lowest file on the CSV so you must run the scraper script before starting the bot training. Because of this you can start and stop the scraper whenever you want to start and stop training the bot and restart it up again on the same CSV.

The initial training script creates the bot and creates a graph at the end of the training. **Make sure the scraper script is running first.** It will print out messages as it is trading. The bot starts at a high epsilon which means it makes more random decisions but decreases as it goes along. You can change the amount of episodes and steps that it runs as it trains if you want. It is set to 50 episodes with 200 steps, each step is a decision it has made: BUY, SELL, HOLD. Some research says an ideal amount of episodes for a bot that could actually do anything successful is at minimum 10,000 (50 episodes is a pretty small start ) but that takes a lot of training time which is why there is the script to continue training. It is a reward based system. It gets a bonus reward if it sells higher than it bought and a negative reward if it makes a sells lower than it bought. The bot trades with all of the account so it gets punished if it sells when it is holding nothing or buys when it is already holding something. There is also a negative reward after each step if the bot hasn't bought anything for the first 35 steps. After all of the training you will get a graph of the account value as the episodes go. You will also get a final epsilon value because it will not have decayed to the lowest amount. You will want to note that value for when you continue training. You will also get a file name for the trained bot in .keras format. You can load this into the continue training script. 

The continue training script is very similar to the initial with a little tweaking. It has a lower reward bonus and negative bonus during trades and it has a little bit of a negative reward for each transaction so it doesnt make lots of very small trades. You need to load in your initial model and you will get another model back. Not sure if this is better than training the same one over and over, but when you want to train again you feed in the new model, change the name of the output model, and get a new one as a result. Again remember to run the scraper script first.
